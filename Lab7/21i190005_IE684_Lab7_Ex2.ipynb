{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190005_IE684_Lab7_Ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**EXERCISE-2**"
      ],
      "metadata": {
        "id": "lOtP764EUS8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRhPKFh4LSeX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "np.random.seed(1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "wvDFyM5yMBSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf(x,lamda, A,y):\n",
        "  assert type(x) is np.ndarray \n",
        "  return (lamda/2)*np.matmul(x.T,x)+0.5*(np.linalg.norm(np.matmul(A,x) - y))**2"
      ],
      "metadata": {
        "id": "xaBqf4lrMCQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x, lamda, A,y):\n",
        "  assert type(x) is np.ndarray\n",
        "  return np.add(np.matmul(A.T, np.subtract(np.matmul(A, x), y)), lamda * x)"
      ],
      "metadata": {
        "id": "KgrnjqDUMt3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalh(x, lamda, A,y):\n",
        "  assert type(x) is np.ndarray\n",
        "  return np.add(np.matmul(A.T,A), lamda * np.identity(len(x)))"
      ],
      "metadata": {
        "id": "dJfgvvvhM1x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BACKTRACKING_LINE_SEARCH = 1"
      ],
      "metadata": {
        "id": "oyKznAjTM77I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking_scaled_direction(x, gradf, direction, alpha_start, rho, gamma,lamda,A,y):\n",
        "  assert type(x) is np.ndarray\n",
        "  assert type(gradf) is np.ndarray \n",
        "  assert type(direction) is np.ndarray \n",
        "  assert type(alpha_start) is float and alpha_start>=0. \n",
        "  assert type(rho) is float and rho>=0.\n",
        "  assert type(gamma) is float and gamma>=0. \n",
        "  \n",
        "  alpha = alpha_start\n",
        "  while evalf(x+alpha*direction, lamda, A,y) > (evalf(x,lamda,A,y) + gamma*alpha*np.matmul(gradf.T,direction)):\n",
        "    alpha=rho*alpha\n",
        "\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "IMyvKVWFM-No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer_Newton(A, y, start_x, tol, line_search_type,lamda, *args):\n",
        "  assert type(start_x) is np.ndarray\n",
        "  assert type(tol) is float and tol>=0 \n",
        "  \n",
        "  x = start_x\n",
        "  g_x = evalg(x,lamda,A,y)\n",
        "\n",
        "  alpha_start = float(args[0])\n",
        "  rho = float(args[1])\n",
        "  gamma = float(args[2])\n",
        "\n",
        "  k = 0\n",
        "  while (np.linalg.norm(g_x) > tol):\n",
        "    D_k = np.linalg.inv(evalh(x,lamda, A,y))\n",
        "    p_k = -np.matmul(D_k,g_x)\n",
        "    step_length = compute_steplength_backtracking_scaled_direction(x, g_x,p_k, alpha_start, rho, gamma,lamda,A,y) \n",
        "\n",
        "    x = np.subtract(x, np.multiply(step_length,np.matmul(D_k, g_x)))\n",
        "    k += 1\n",
        "    g_x = evalg(x,lamda, A,y) \n",
        "\n",
        "  return x,  k, evalf(x,lamda,A,y)"
      ],
      "metadata": {
        "id": "-wvF9C30NKGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer_BFGS(A,y, start_x, tol, line_search_type, lamda, *args):\n",
        "  assert type(start_x) is np.ndarray \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  \n",
        "  x = start_x\n",
        "  g_x = evalg(x, lamda,A,y)\n",
        "  I = np.identity(len(x))\n",
        "  B_k = I\n",
        "\n",
        "  alpha_start = float(args[0])\n",
        "  rho = float(args[1])\n",
        "  gamma = float(args[2])\n",
        "\n",
        "  k = 0\n",
        "  while (np.linalg.norm(g_x) > tol): \n",
        "    p_k = -np.matmul(B_k, g_x)\n",
        "    step_length = compute_steplength_backtracking_scaled_direction(x, g_x,p_k, alpha_start, rho, gamma,lamda,A,y)\n",
        "\n",
        "    x_prev = x\n",
        "    s_k = np.multiply(step_length,p_k) \n",
        "    x = np.add(x, s_k)\n",
        "    y_k = evalg(x,lamda, A,y)-evalg(x_prev,lamda, A,y)\n",
        "\n",
        "    u_k = 1/(np.matmul(y_k.T,s_k))\n",
        "    term_1 = np.subtract(I , u_k*np.matmul(s_k,y_k.T))\n",
        "    term_2 = np.subtract(I , u_k*np.matmul(y_k, s_k.T))\n",
        "    B_k = np.matmul(np.matmul(term_1,B_k), term_2) + u_k*np.matmul(s_k,s_k.T)\n",
        "\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x,lamda, A,y) #compute gradient at new point\n",
        "\n",
        "  return x , k, evalf(x,lamda, A,y)"
      ],
      "metadata": {
        "id": "hSr9zd1VNYkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200\n",
        "ds = [1000, 5000, 10000, 20000, 25000, 50000, 100000, 200000, 500000, 1000000]\n",
        "lamda_reg = 0.001\n",
        "eps = np.random.randn(N,1)\n",
        "\n",
        "for  i in range(np.size(ds)):\n",
        "  d = ds[i]\n",
        "  A = np.random.randn(N,d)\n",
        "  for j in range(A.shape[1]):\n",
        "    A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "\n",
        "  xorig = np.ones((d,1))\n",
        "  y = np.dot(A, xorig) + eps\n",
        "  n = len(xorig)\n",
        "  my_tol= 1e-3\n",
        "  lamda = 0.001\n",
        "  start  = timeit.default_timer()\n",
        "  x, k, f_value = find_minimizer_Newton(A,y, xorig , my_tol, BACKTRACKING_LINE_SEARCH,lamda, 0.9 , 0.5, 0.5)\n",
        "  newtontime = timeit.default_timer() - start\n",
        "  \n",
        "  start_bfgs  = timeit.default_timer()\n",
        "  x_bfgs, k_bfgs,f_value_bfgs = find_minimizer_BFGS(A,y, xorig , my_tol, BACKTRACKING_LINE_SEARCH,lamda, 0.9 , 0.5, 0.5)\n",
        "  bfgstime = timeit.default_timer() - start_bfgs\n",
        "   \n",
        "  print(\"\\nFor d = \", d)\n",
        "  print(\"For Newton: \")\n",
        "  print(\"time: \", newtontime )\n",
        "  print(\"||Ax_opt - y||^2 :\", (np.linalg.norm(np.matmul(A,x) - y))**2)\n",
        "  print(\" ||x_opt-xorig||^2 :\", (np.linalg.norm(x - xorig))**2)\n",
        "  print(\"For BFGS: \")\n",
        "  print(\"time: \", bfgstime )\n",
        "  print(\"||Ax_opt - y||^2 :\", (np.linalg.norm(np.matmul(A,x_bfgs) - y))**2)\n",
        "  print(\" ||x_opt-xorig||^2 :\", (np.linalg.norm(x_bfgs - xorig))**2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WnD2IQ8O-Yp",
        "outputId": "32c65dde-bd60-436b-eed7-893259566e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For d =  1000\n",
            "For Newton: \n",
            "time:  1.1063840599999821\n",
            "||Ax_opt - y||^2 : 5.77140010314599e-05\n",
            " ||x_opt-xorig||^2 : 865.2979971977057\n",
            "For BFGS: \n",
            "time:  7.343680744000267\n",
            "||Ax_opt - y||^2 : 5.571737379621836e-05\n",
            " ||x_opt-xorig||^2 : 865.3523026794429\n",
            "\n",
            "For d =  5000\n",
            "For Newton: \n",
            "time:  54.6139351769998\n",
            "||Ax_opt - y||^2 : 9.949803059501234e-06\n",
            " ||x_opt-xorig||^2 : 4783.586019993549\n",
            "For BFGS: \n",
            "time:  654.59976018\n",
            "||Ax_opt - y||^2 : 9.7776996902963e-06\n",
            " ||x_opt-xorig||^2 : 4783.669438585895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For Newton method session crashed at d = 10000\n",
        "\n",
        "#For BFGS method session crashed at d = 10000 ."
      ],
      "metadata": {
        "id": "auuQOoPkUy7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UdXpqqKwUud1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}